{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Shuffling Batches\n",
    "Shuffling batches refers to the act of shuffling the training data each epoch and producing different batches, as opposed to only shuffling the data once at the beginning and producing an identical set of batches each epoch.\n",
    "\n",
    "First thing to point out is that using the ReLU activation in regression can cause the model loss blow up sometimes. The analysis is performed with these large values left in the data. Normally I would not consider models would for comparison, but I wish to measure what performance from the first $n$ trained models, rather than the first $n$ successful models. \n",
    "\n",
    "Also due to the different loss metrics being used in regression and classification (RMSE & negative log loss) they are hard to compare, e.g. at what point is a RMSE measurement equivalent to a log loss measurement?. For this reason the comparisons containing both learning tasks should be considered carefully.\n",
    "\n",
    "For hypothesis testing Welch's t-test is used, with a threshold of .001 for the p-value.\n",
    "\n",
    "## Summary\n",
    "Shuffling batches seems to benefit generalisation ability the most, and is at times harmful to test performance. \n",
    "\n",
    "Some guidelines derived from the analyses:\n",
    "- Shuffling batches improves validation accuracy.\n",
    "- Shuffling batches is not beneficial when the goal is to evaluate the ability to learn the data and generalisation is not expected (e.g. for toy datasets such as XOR).\n",
    "- Shuffling batches is always recommended when working on classification tasks. \n",
    "\n",
    "A general piece of advice: \n",
    "- Do to not use ReLU on regression tasks unless you are willing to spend more time than usual tuning hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/anthony/420/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4536 entries, ce2406bc88ceda4e2fde96bf96fdd2d5 to 9591fefef4086cbf060bc6afdcee4eba\n",
      "Columns: 168 entries, activation_func to val_loss_39\n",
      "dtypes: bool(1), float64(163), int64(1), object(3)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../scripts/results_summary.csv', index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>gaussian_noise</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>momentum</th>\n",
       "      <th>train_loss_00</th>\n",
       "      <th>train_loss_01</th>\n",
       "      <th>train_loss_02</th>\n",
       "      <th>train_loss_03</th>\n",
       "      <th>train_loss_04</th>\n",
       "      <th>train_loss_05</th>\n",
       "      <th>...</th>\n",
       "      <th>val_loss_30</th>\n",
       "      <th>val_loss_31</th>\n",
       "      <th>val_loss_32</th>\n",
       "      <th>val_loss_33</th>\n",
       "      <th>val_loss_34</th>\n",
       "      <th>val_loss_35</th>\n",
       "      <th>val_loss_36</th>\n",
       "      <th>val_loss_37</th>\n",
       "      <th>val_loss_38</th>\n",
       "      <th>val_loss_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4536.000000</td>\n",
       "      <td>4536.000000</td>\n",
       "      <td>4536.000000</td>\n",
       "      <td>4536.000000</td>\n",
       "      <td>4.469000e+03</td>\n",
       "      <td>4.465000e+03</td>\n",
       "      <td>4.474000e+03</td>\n",
       "      <td>4.460000e+03</td>\n",
       "      <td>4.468000e+03</td>\n",
       "      <td>4.480000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.291000e+03</td>\n",
       "      <td>1.291000e+03</td>\n",
       "      <td>1.291000e+03</td>\n",
       "      <td>1.293000e+03</td>\n",
       "      <td>1.284000e+03</td>\n",
       "      <td>1.289000e+03</td>\n",
       "      <td>1.286000e+03</td>\n",
       "      <td>1.287000e+03</td>\n",
       "      <td>1.285000e+03</td>\n",
       "      <td>1.288000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.238095</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>6.139973e+148</td>\n",
       "      <td>1.178551e+143</td>\n",
       "      <td>2.240893e+146</td>\n",
       "      <td>1.080856e+143</td>\n",
       "      <td>5.007608e+146</td>\n",
       "      <td>1.060628e+132</td>\n",
       "      <td>...</td>\n",
       "      <td>3.490164e+139</td>\n",
       "      <td>1.192571e+140</td>\n",
       "      <td>6.523714e+144</td>\n",
       "      <td>3.004334e+88</td>\n",
       "      <td>5.270054e+87</td>\n",
       "      <td>2.447946e+133</td>\n",
       "      <td>2.201866e+139</td>\n",
       "      <td>7.127668e+127</td>\n",
       "      <td>1.836580e+128</td>\n",
       "      <td>4.176261e+140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.432443</td>\n",
       "      <td>0.044974</td>\n",
       "      <td>0.044704</td>\n",
       "      <td>0.368219</td>\n",
       "      <td>4.104608e+150</td>\n",
       "      <td>7.788403e+144</td>\n",
       "      <td>1.498695e+148</td>\n",
       "      <td>7.218305e+144</td>\n",
       "      <td>3.347240e+148</td>\n",
       "      <td>7.099082e+133</td>\n",
       "      <td>...</td>\n",
       "      <td>1.254033e+141</td>\n",
       "      <td>4.284966e+141</td>\n",
       "      <td>2.344002e+146</td>\n",
       "      <td>1.079347e+90</td>\n",
       "      <td>1.846660e+89</td>\n",
       "      <td>8.788773e+134</td>\n",
       "      <td>7.896076e+140</td>\n",
       "      <td>2.557036e+129</td>\n",
       "      <td>6.583569e+129</td>\n",
       "      <td>1.498806e+142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.878009e-12</td>\n",
       "      <td>1.887379e-15</td>\n",
       "      <td>6.075696e-14</td>\n",
       "      <td>1.249001e-15</td>\n",
       "      <td>2.439715e-14</td>\n",
       "      <td>7.771561e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.205098e-02</td>\n",
       "      <td>4.532566e-03</td>\n",
       "      <td>4.032520e-03</td>\n",
       "      <td>8.639882e-07</td>\n",
       "      <td>2.478734e-02</td>\n",
       "      <td>9.347693e-04</td>\n",
       "      <td>1.913314e-02</td>\n",
       "      <td>1.281576e-02</td>\n",
       "      <td>3.864593e-03</td>\n",
       "      <td>1.995955e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.304792e-01</td>\n",
       "      <td>2.317160e-01</td>\n",
       "      <td>2.297833e-01</td>\n",
       "      <td>2.342466e-01</td>\n",
       "      <td>2.307808e-01</td>\n",
       "      <td>2.303364e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.340462e-01</td>\n",
       "      <td>1.338613e-01</td>\n",
       "      <td>1.409296e-01</td>\n",
       "      <td>1.371336e-01</td>\n",
       "      <td>1.328476e-01</td>\n",
       "      <td>1.330931e-01</td>\n",
       "      <td>1.354859e-01</td>\n",
       "      <td>1.379978e-01</td>\n",
       "      <td>1.337317e-01</td>\n",
       "      <td>1.374174e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.006268e-01</td>\n",
       "      <td>5.005960e-01</td>\n",
       "      <td>5.009687e-01</td>\n",
       "      <td>5.008767e-01</td>\n",
       "      <td>5.006290e-01</td>\n",
       "      <td>5.009712e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.280760e-01</td>\n",
       "      <td>2.075429e-01</td>\n",
       "      <td>2.246615e-01</td>\n",
       "      <td>2.367095e-01</td>\n",
       "      <td>2.146115e-01</td>\n",
       "      <td>2.205804e-01</td>\n",
       "      <td>2.219849e-01</td>\n",
       "      <td>2.380792e-01</td>\n",
       "      <td>2.077034e-01</td>\n",
       "      <td>2.332943e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>6.950951e-01</td>\n",
       "      <td>6.948118e-01</td>\n",
       "      <td>6.947904e-01</td>\n",
       "      <td>6.948717e-01</td>\n",
       "      <td>6.953892e-01</td>\n",
       "      <td>6.954834e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.588411e-01</td>\n",
       "      <td>3.450229e-01</td>\n",
       "      <td>3.522622e-01</td>\n",
       "      <td>3.709971e-01</td>\n",
       "      <td>3.579938e-01</td>\n",
       "      <td>3.465480e-01</td>\n",
       "      <td>3.506236e-01</td>\n",
       "      <td>3.654653e-01</td>\n",
       "      <td>3.506442e-01</td>\n",
       "      <td>3.557505e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>2.743954e+152</td>\n",
       "      <td>5.203949e+146</td>\n",
       "      <td>1.002447e+150</td>\n",
       "      <td>4.820618e+146</td>\n",
       "      <td>2.237399e+150</td>\n",
       "      <td>4.751615e+135</td>\n",
       "      <td>...</td>\n",
       "      <td>4.505802e+142</td>\n",
       "      <td>1.539609e+143</td>\n",
       "      <td>8.422115e+147</td>\n",
       "      <td>3.881150e+91</td>\n",
       "      <td>6.615518e+90</td>\n",
       "      <td>3.155402e+136</td>\n",
       "      <td>2.831599e+142</td>\n",
       "      <td>9.173309e+130</td>\n",
       "      <td>2.360005e+131</td>\n",
       "      <td>5.379024e+143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        batch_size  gaussian_noise  learning_rate     momentum  train_loss_00  \\\n",
       "count  4536.000000     4536.000000    4536.000000  4536.000000   4.469000e+03   \n",
       "mean      3.238095        0.036667       0.037000     0.466667  6.139973e+148   \n",
       "std       7.432443        0.044974       0.044704     0.368219  4.104608e+150   \n",
       "min      -1.000000        0.000000       0.001000     0.000000   3.878009e-12   \n",
       "25%      -1.000000        0.000000       0.001000     0.000000   2.304792e-01   \n",
       "50%       1.000000        0.010000       0.010000     0.500000   5.006268e-01   \n",
       "75%       2.000000        0.100000       0.100000     0.900000   6.950951e-01   \n",
       "max      32.000000        0.100000       0.100000     0.900000  2.743954e+152   \n",
       "\n",
       "       train_loss_01  train_loss_02  train_loss_03  train_loss_04  \\\n",
       "count   4.465000e+03   4.474000e+03   4.460000e+03   4.468000e+03   \n",
       "mean   1.178551e+143  2.240893e+146  1.080856e+143  5.007608e+146   \n",
       "std    7.788403e+144  1.498695e+148  7.218305e+144  3.347240e+148   \n",
       "min     1.887379e-15   6.075696e-14   1.249001e-15   2.439715e-14   \n",
       "25%     2.317160e-01   2.297833e-01   2.342466e-01   2.307808e-01   \n",
       "50%     5.005960e-01   5.009687e-01   5.008767e-01   5.006290e-01   \n",
       "75%     6.948118e-01   6.947904e-01   6.948717e-01   6.953892e-01   \n",
       "max    5.203949e+146  1.002447e+150  4.820618e+146  2.237399e+150   \n",
       "\n",
       "       train_loss_05  ...    val_loss_30    val_loss_31    val_loss_32  \\\n",
       "count   4.480000e+03  ...   1.291000e+03   1.291000e+03   1.291000e+03   \n",
       "mean   1.060628e+132  ...  3.490164e+139  1.192571e+140  6.523714e+144   \n",
       "std    7.099082e+133  ...  1.254033e+141  4.284966e+141  2.344002e+146   \n",
       "min     7.771561e-16  ...   1.205098e-02   4.532566e-03   4.032520e-03   \n",
       "25%     2.303364e-01  ...   1.340462e-01   1.338613e-01   1.409296e-01   \n",
       "50%     5.009712e-01  ...   2.280760e-01   2.075429e-01   2.246615e-01   \n",
       "75%     6.954834e-01  ...   3.588411e-01   3.450229e-01   3.522622e-01   \n",
       "max    4.751615e+135  ...  4.505802e+142  1.539609e+143  8.422115e+147   \n",
       "\n",
       "        val_loss_33   val_loss_34    val_loss_35    val_loss_36  \\\n",
       "count  1.293000e+03  1.284000e+03   1.289000e+03   1.286000e+03   \n",
       "mean   3.004334e+88  5.270054e+87  2.447946e+133  2.201866e+139   \n",
       "std    1.079347e+90  1.846660e+89  8.788773e+134  7.896076e+140   \n",
       "min    8.639882e-07  2.478734e-02   9.347693e-04   1.913314e-02   \n",
       "25%    1.371336e-01  1.328476e-01   1.330931e-01   1.354859e-01   \n",
       "50%    2.367095e-01  2.146115e-01   2.205804e-01   2.219849e-01   \n",
       "75%    3.709971e-01  3.579938e-01   3.465480e-01   3.506236e-01   \n",
       "max    3.881150e+91  6.615518e+90  3.155402e+136  2.831599e+142   \n",
       "\n",
       "         val_loss_37    val_loss_38    val_loss_39  \n",
       "count   1.287000e+03   1.285000e+03   1.288000e+03  \n",
       "mean   7.127668e+127  1.836580e+128  4.176261e+140  \n",
       "std    2.557036e+129  6.583569e+129  1.498806e+142  \n",
       "min     1.281576e-02   3.864593e-03   1.995955e-02  \n",
       "25%     1.379978e-01   1.337317e-01   1.374174e-01  \n",
       "50%     2.380792e-01   2.077034e-01   2.332943e-01  \n",
       "75%     3.654653e-01   3.506442e-01   3.557505e-01  \n",
       "max    9.173309e+130  2.360005e+131  5.379024e+143  \n",
       "\n",
       "[8 rows x 164 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>gaussian_noise</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>momentum</th>\n",
       "      <th>train_loss_00</th>\n",
       "      <th>train_loss_01</th>\n",
       "      <th>train_loss_02</th>\n",
       "      <th>train_loss_03</th>\n",
       "      <th>train_loss_04</th>\n",
       "      <th>train_loss_05</th>\n",
       "      <th>...</th>\n",
       "      <th>val_loss_30</th>\n",
       "      <th>val_loss_31</th>\n",
       "      <th>val_loss_32</th>\n",
       "      <th>val_loss_33</th>\n",
       "      <th>val_loss_34</th>\n",
       "      <th>val_loss_35</th>\n",
       "      <th>val_loss_36</th>\n",
       "      <th>val_loss_37</th>\n",
       "      <th>val_loss_38</th>\n",
       "      <th>val_loss_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4536.000000</td>\n",
       "      <td>4536.000000</td>\n",
       "      <td>4536.000000</td>\n",
       "      <td>4536.000000</td>\n",
       "      <td>4.421000e+03</td>\n",
       "      <td>4.408000e+03</td>\n",
       "      <td>4.420000e+03</td>\n",
       "      <td>4.409000e+03</td>\n",
       "      <td>4.416000e+03</td>\n",
       "      <td>4.424000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1269.000000</td>\n",
       "      <td>1274.000000</td>\n",
       "      <td>1274.000000</td>\n",
       "      <td>1.276000e+03</td>\n",
       "      <td>1265.000000</td>\n",
       "      <td>1270.000000</td>\n",
       "      <td>1269.000000</td>\n",
       "      <td>1269.000000</td>\n",
       "      <td>1270.000000</td>\n",
       "      <td>1275.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.238095</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>9.492196e-01</td>\n",
       "      <td>9.856368e-01</td>\n",
       "      <td>9.650471e-01</td>\n",
       "      <td>1.008959e+00</td>\n",
       "      <td>9.500885e-01</td>\n",
       "      <td>9.786358e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662106</td>\n",
       "      <td>0.602162</td>\n",
       "      <td>0.851149</td>\n",
       "      <td>6.383636e-01</td>\n",
       "      <td>0.673178</td>\n",
       "      <td>0.563561</td>\n",
       "      <td>0.570689</td>\n",
       "      <td>0.644398</td>\n",
       "      <td>0.778400</td>\n",
       "      <td>0.717671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.432443</td>\n",
       "      <td>0.044974</td>\n",
       "      <td>0.044704</td>\n",
       "      <td>0.368219</td>\n",
       "      <td>2.551082e+00</td>\n",
       "      <td>3.058140e+00</td>\n",
       "      <td>2.717477e+00</td>\n",
       "      <td>3.221689e+00</td>\n",
       "      <td>2.714989e+00</td>\n",
       "      <td>2.986081e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.273116</td>\n",
       "      <td>2.011437</td>\n",
       "      <td>4.774636</td>\n",
       "      <td>2.011593e+00</td>\n",
       "      <td>2.559179</td>\n",
       "      <td>1.751126</td>\n",
       "      <td>1.892626</td>\n",
       "      <td>2.650772</td>\n",
       "      <td>4.349055</td>\n",
       "      <td>2.965329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.878009e-12</td>\n",
       "      <td>1.887379e-15</td>\n",
       "      <td>6.075696e-14</td>\n",
       "      <td>1.249001e-15</td>\n",
       "      <td>2.439715e-14</td>\n",
       "      <td>7.771561e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012051</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>8.639882e-07</td>\n",
       "      <td>0.024787</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.019133</td>\n",
       "      <td>0.012816</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.019960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.290924e-01</td>\n",
       "      <td>2.293545e-01</td>\n",
       "      <td>2.277254e-01</td>\n",
       "      <td>2.324011e-01</td>\n",
       "      <td>2.281162e-01</td>\n",
       "      <td>2.264769e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133462</td>\n",
       "      <td>0.133300</td>\n",
       "      <td>0.140651</td>\n",
       "      <td>1.369765e-01</td>\n",
       "      <td>0.132286</td>\n",
       "      <td>0.132207</td>\n",
       "      <td>0.134755</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>0.133561</td>\n",
       "      <td>0.136948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.004064e-01</td>\n",
       "      <td>5.004145e-01</td>\n",
       "      <td>5.006733e-01</td>\n",
       "      <td>5.006643e-01</td>\n",
       "      <td>5.004337e-01</td>\n",
       "      <td>5.006053e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215599</td>\n",
       "      <td>0.203238</td>\n",
       "      <td>0.215326</td>\n",
       "      <td>2.264593e-01</td>\n",
       "      <td>0.202375</td>\n",
       "      <td>0.213418</td>\n",
       "      <td>0.216666</td>\n",
       "      <td>0.228667</td>\n",
       "      <td>0.203096</td>\n",
       "      <td>0.229127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>6.946095e-01</td>\n",
       "      <td>6.943673e-01</td>\n",
       "      <td>6.944147e-01</td>\n",
       "      <td>6.943980e-01</td>\n",
       "      <td>6.948703e-01</td>\n",
       "      <td>6.947385e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340059</td>\n",
       "      <td>0.336998</td>\n",
       "      <td>0.344854</td>\n",
       "      <td>3.642472e-01</td>\n",
       "      <td>0.347973</td>\n",
       "      <td>0.337470</td>\n",
       "      <td>0.341807</td>\n",
       "      <td>0.352550</td>\n",
       "      <td>0.338966</td>\n",
       "      <td>0.345505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>4.329897e+01</td>\n",
       "      <td>9.937854e+01</td>\n",
       "      <td>6.472528e+01</td>\n",
       "      <td>9.880452e+01</td>\n",
       "      <td>9.643732e+01</td>\n",
       "      <td>8.603724e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>85.228314</td>\n",
       "      <td>22.081121</td>\n",
       "      <td>93.338842</td>\n",
       "      <td>2.035628e+01</td>\n",
       "      <td>43.754461</td>\n",
       "      <td>13.815511</td>\n",
       "      <td>29.434711</td>\n",
       "      <td>54.095100</td>\n",
       "      <td>98.826480</td>\n",
       "      <td>58.866476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        batch_size  gaussian_noise  learning_rate     momentum  train_loss_00  \\\n",
       "count  4536.000000     4536.000000    4536.000000  4536.000000   4.421000e+03   \n",
       "mean      3.238095        0.036667       0.037000     0.466667   9.492196e-01   \n",
       "std       7.432443        0.044974       0.044704     0.368219   2.551082e+00   \n",
       "min      -1.000000        0.000000       0.001000     0.000000   3.878009e-12   \n",
       "25%      -1.000000        0.000000       0.001000     0.000000   2.290924e-01   \n",
       "50%       1.000000        0.010000       0.010000     0.500000   5.004064e-01   \n",
       "75%       2.000000        0.100000       0.100000     0.900000   6.946095e-01   \n",
       "max      32.000000        0.100000       0.100000     0.900000   4.329897e+01   \n",
       "\n",
       "       train_loss_01  train_loss_02  train_loss_03  train_loss_04  \\\n",
       "count   4.408000e+03   4.420000e+03   4.409000e+03   4.416000e+03   \n",
       "mean    9.856368e-01   9.650471e-01   1.008959e+00   9.500885e-01   \n",
       "std     3.058140e+00   2.717477e+00   3.221689e+00   2.714989e+00   \n",
       "min     1.887379e-15   6.075696e-14   1.249001e-15   2.439715e-14   \n",
       "25%     2.293545e-01   2.277254e-01   2.324011e-01   2.281162e-01   \n",
       "50%     5.004145e-01   5.006733e-01   5.006643e-01   5.004337e-01   \n",
       "75%     6.943673e-01   6.944147e-01   6.943980e-01   6.948703e-01   \n",
       "max     9.937854e+01   6.472528e+01   9.880452e+01   9.643732e+01   \n",
       "\n",
       "       train_loss_05  ...  val_loss_30  val_loss_31  val_loss_32  \\\n",
       "count   4.424000e+03  ...  1269.000000  1274.000000  1274.000000   \n",
       "mean    9.786358e-01  ...     0.662106     0.602162     0.851149   \n",
       "std     2.986081e+00  ...     3.273116     2.011437     4.774636   \n",
       "min     7.771561e-16  ...     0.012051     0.004533     0.004033   \n",
       "25%     2.264769e-01  ...     0.133462     0.133300     0.140651   \n",
       "50%     5.006053e-01  ...     0.215599     0.203238     0.215326   \n",
       "75%     6.947385e-01  ...     0.340059     0.336998     0.344854   \n",
       "max     8.603724e+01  ...    85.228314    22.081121    93.338842   \n",
       "\n",
       "        val_loss_33  val_loss_34  val_loss_35  val_loss_36  val_loss_37  \\\n",
       "count  1.276000e+03  1265.000000  1270.000000  1269.000000  1269.000000   \n",
       "mean   6.383636e-01     0.673178     0.563561     0.570689     0.644398   \n",
       "std    2.011593e+00     2.559179     1.751126     1.892626     2.650772   \n",
       "min    8.639882e-07     0.024787     0.000935     0.019133     0.012816   \n",
       "25%    1.369765e-01     0.132286     0.132207     0.134755     0.137504   \n",
       "50%    2.264593e-01     0.202375     0.213418     0.216666     0.228667   \n",
       "75%    3.642472e-01     0.347973     0.337470     0.341807     0.352550   \n",
       "max    2.035628e+01    43.754461    13.815511    29.434711    54.095100   \n",
       "\n",
       "       val_loss_38  val_loss_39  \n",
       "count  1270.000000  1275.000000  \n",
       "mean      0.778400     0.717671  \n",
       "std       4.349055     2.965329  \n",
       "min       0.003865     0.019960  \n",
       "25%       0.133561     0.136948  \n",
       "50%       0.203096     0.229127  \n",
       "75%       0.338966     0.345505  \n",
       "max      98.826480    58.866476  \n",
       "\n",
       "[8 rows x 164 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_func</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>clf_type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>gaussian_noise</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>momentum</th>\n",
       "      <th>shuffle_batches</th>\n",
       "      <th>train_loss_00</th>\n",
       "      <th>train_loss_01</th>\n",
       "      <th>...</th>\n",
       "      <th>val_loss_30</th>\n",
       "      <th>val_loss_31</th>\n",
       "      <th>val_loss_32</th>\n",
       "      <th>val_loss_33</th>\n",
       "      <th>val_loss_34</th>\n",
       "      <th>val_loss_35</th>\n",
       "      <th>val_loss_36</th>\n",
       "      <th>val_loss_37</th>\n",
       "      <th>val_loss_38</th>\n",
       "      <th>val_loss_39</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ce2406bc88ceda4e2fde96bf96fdd2d5</th>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>xor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>5.166794e-01</td>\n",
       "      <td>5.365412e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745da0d20037327f586babfb38077b62</th>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>xor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>False</td>\n",
       "      <td>4.087733e-01</td>\n",
       "      <td>1.385021e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aeeec51b4e4d9c885bd53d0de5c46b14</th>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>xor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>3.247473e-01</td>\n",
       "      <td>4.423432e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a99a2a1ecd0377d4d4d5c47d3015771b</th>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>xor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>6.579213e-01</td>\n",
       "      <td>3.202256e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a523da2d87ca23feb5411114cf717710</th>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>1</td>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>xor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>5.498153e+38</td>\n",
       "      <td>1.364288e+14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 activation_func  batch_size      clf_type  \\\n",
       "run_id                                                                       \n",
       "ce2406bc88ceda4e2fde96bf96fdd2d5       LeakyReLU           1  MLPRegressor   \n",
       "745da0d20037327f586babfb38077b62       LeakyReLU           1  MLPRegressor   \n",
       "aeeec51b4e4d9c885bd53d0de5c46b14       LeakyReLU           1  MLPRegressor   \n",
       "a99a2a1ecd0377d4d4d5c47d3015771b       LeakyReLU           1  MLPRegressor   \n",
       "a523da2d87ca23feb5411114cf717710       LeakyReLU           1  MLPRegressor   \n",
       "\n",
       "                                 dataset  gaussian_noise  learning_rate  \\\n",
       "run_id                                                                    \n",
       "ce2406bc88ceda4e2fde96bf96fdd2d5     xor             0.0            0.1   \n",
       "745da0d20037327f586babfb38077b62     xor             0.0            0.1   \n",
       "aeeec51b4e4d9c885bd53d0de5c46b14     xor             0.0            0.1   \n",
       "a99a2a1ecd0377d4d4d5c47d3015771b     xor             0.0            0.1   \n",
       "a523da2d87ca23feb5411114cf717710     xor             0.0            0.1   \n",
       "\n",
       "                                  momentum  shuffle_batches  train_loss_00  \\\n",
       "run_id                                                                       \n",
       "ce2406bc88ceda4e2fde96bf96fdd2d5       0.9             True   5.166794e-01   \n",
       "745da0d20037327f586babfb38077b62       0.9            False   4.087733e-01   \n",
       "aeeec51b4e4d9c885bd53d0de5c46b14       0.5             True   3.247473e-01   \n",
       "a99a2a1ecd0377d4d4d5c47d3015771b       0.5            False   6.579213e-01   \n",
       "a523da2d87ca23feb5411114cf717710       0.0             True   5.498153e+38   \n",
       "\n",
       "                                  train_loss_01  ...  val_loss_30  \\\n",
       "run_id                                           ...                \n",
       "ce2406bc88ceda4e2fde96bf96fdd2d5   5.365412e-01  ...          NaN   \n",
       "745da0d20037327f586babfb38077b62   1.385021e-10  ...          NaN   \n",
       "aeeec51b4e4d9c885bd53d0de5c46b14   4.423432e-06  ...          NaN   \n",
       "a99a2a1ecd0377d4d4d5c47d3015771b   3.202256e-01  ...          NaN   \n",
       "a523da2d87ca23feb5411114cf717710   1.364288e+14  ...          NaN   \n",
       "\n",
       "                                  val_loss_31  val_loss_32  val_loss_33  \\\n",
       "run_id                                                                    \n",
       "ce2406bc88ceda4e2fde96bf96fdd2d5          NaN          NaN          NaN   \n",
       "745da0d20037327f586babfb38077b62          NaN          NaN          NaN   \n",
       "aeeec51b4e4d9c885bd53d0de5c46b14          NaN          NaN          NaN   \n",
       "a99a2a1ecd0377d4d4d5c47d3015771b          NaN          NaN          NaN   \n",
       "a523da2d87ca23feb5411114cf717710          NaN          NaN          NaN   \n",
       "\n",
       "                                  val_loss_34  val_loss_35  val_loss_36  \\\n",
       "run_id                                                                    \n",
       "ce2406bc88ceda4e2fde96bf96fdd2d5          NaN          NaN          NaN   \n",
       "745da0d20037327f586babfb38077b62          NaN          NaN          NaN   \n",
       "aeeec51b4e4d9c885bd53d0de5c46b14          NaN          NaN          NaN   \n",
       "a99a2a1ecd0377d4d4d5c47d3015771b          NaN          NaN          NaN   \n",
       "a523da2d87ca23feb5411114cf717710          NaN          NaN          NaN   \n",
       "\n",
       "                                  val_loss_37  val_loss_38  val_loss_39  \n",
       "run_id                                                                   \n",
       "ce2406bc88ceda4e2fde96bf96fdd2d5          NaN          NaN          NaN  \n",
       "745da0d20037327f586babfb38077b62          NaN          NaN          NaN  \n",
       "aeeec51b4e4d9c885bd53d0de5c46b14          NaN          NaN          NaN  \n",
       "a99a2a1ecd0377d4d4d5c47d3015771b          NaN          NaN          NaN  \n",
       "a523da2d87ca23feb5411114cf717710          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['train_loss', 'train_scores', 'val_loss', 'val_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(dataframe, name='a'):\n",
    "    a = dataframe\n",
    "    print('Summary for %s:' % name)\n",
    "    print('n: %d' % len(a.dropna()))\n",
    "    # Do aggregate functions (e.g. mean()) twice to get column-wise and then datafram-wise measures.\n",
    "    print('min: %.4e - max: %.4e' % (a.min().min(), a.max().max()))\n",
    "    print('μ ± 2σ: %.4e ± %.4e' % (a.mean().mean(), 2 * a.std().std()))\n",
    "    print('Quartiles - 1st: %.4e - 2nd: %.4e - 3rd: %.4e' % (a.quantile(0.25).quantile(0.25),\n",
    "                                                            a.quantile(0.5).quantile(0.5),\n",
    "                                                            a.quantile(0.75).quantile(0.75)))\n",
    "     \n",
    "        \n",
    "def format_p_value(p_value):\n",
    "    return str(p_value % 1)[1:5] if p_value > 0.001 else '<.001'\n",
    "        \n",
    "def stat_test(masks, test_name, alpha=0.001):    \n",
    "    assert len(masks) == 2\n",
    "\n",
    "    print('*' * 80)\n",
    "    print(test_name)\n",
    "    print('*' * 80)\n",
    "    \n",
    "    for metric in metrics:\n",
    "        print('#'  * len(metric))\n",
    "        print(metric)\n",
    "        print('#'  * len(metric))\n",
    "    \n",
    "        a = df[masks[0]].filter(regex=metric + '_\\d{2}')\n",
    "        b = df[masks[1]].filter(regex=metric + '_\\d{2}')\n",
    "    \n",
    "        print_stats(a, name='a')\n",
    "        print()\n",
    "\n",
    "        print_stats(b, name='b')\n",
    "        print()\n",
    "        \n",
    "        print('Welch t-test:')\n",
    "        t, p = stats.ttest_ind(a.values.ravel(), b.values.ravel(), equal_var=False, nan_policy='omit')\n",
    "        print('t: %.4f - p: %s' % (t, format_p_value(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Regression - Shuffling Batches vs. Not Shuffling Batches:\n",
      "********************************************************************************\n",
      "##########\n",
      "train_loss\n",
      "##########\n",
      "Summary for a:\n",
      "n: 1077\n",
      "min: 7.2164e-16 - max: 2.7440e+152\n",
      "μ ± 2σ: 6.5877e+147 ± 2.5883e+150\n",
      "Quartiles - 1st: 1.7842e-01 - 2nd: 3.1288e-01 - 3rd: 5.0199e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 1073\n",
      "min: 1.1102e-16 - max: 2.9061e+153\n",
      "μ ± 2σ: 1.0371e+149 ± 3.0517e+151\n",
      "Quartiles - 1st: 1.7462e-01 - 2nd: 3.0158e-01 - 3rd: 5.0127e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: -1.3314 - p: .410\n",
      "############\n",
      "train_scores\n",
      "############\n",
      "Summary for a:\n",
      "n: 887\n",
      "min: -1.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 5.4695e-01 ± 9.6442e-03\n",
      "Quartiles - 1st: 4.4577e-02 - 2nd: 6.6760e-01 - 3rd: 9.4845e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 791\n",
      "min: -1.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 5.9063e-01 ± 1.6218e-02\n",
      "Quartiles - 1st: 2.3345e-01 - 2nd: 6.7216e-01 - 3rd: 9.4939e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: -14.6843 - p: <.001\n",
      "########\n",
      "val_loss\n",
      "########\n",
      "Summary for a:\n",
      "n: 302\n",
      "min: 5.5038e-02 - max: 8.4221e+147\n",
      "μ ± 2σ: 9.5169e+143 ± 1.6016e+146\n",
      "Quartiles - 1st: 1.4416e-01 - 2nd: 1.9098e-01 - 3rd: 3.1101e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 305\n",
      "min: 6.3192e-02 - max: 4.4136e+149\n",
      "μ ± 2σ: 3.4163e+145 ± 7.7658e+147\n",
      "Quartiles - 1st: 1.5573e-01 - 2nd: 2.7896e-01 - 3rd: 3.3380e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: -0.9721 - p: .509\n",
      "##########\n",
      "val_scores\n",
      "##########\n",
      "Summary for a:\n",
      "n: 302\n",
      "min: -4.6464e-01 - max: 9.9346e-01\n",
      "μ ± 2σ: 7.9645e-01 ± 2.4961e-02\n",
      "Quartiles - 1st: 7.0430e-01 - 2nd: 8.9939e-01 - 3rd: 9.4279e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 306\n",
      "min: -5.0256e-01 - max: 9.9011e-01\n",
      "μ ± 2σ: 7.2051e-01 ± 1.7680e-02\n",
      "Quartiles - 1st: 6.7611e-01 - 2nd: 7.7064e-01 - 3rd: 9.3221e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: 24.9651 - p: <.001\n"
     ]
    }
   ],
   "source": [
    "shuffles_batch = df['shuffle_batches'] == True\n",
    "no_shuffling = df['shuffle_batches'] == False\n",
    "using_regression = df['clf_type'] == 'MLPRegressor'\n",
    "\n",
    "stat_test(masks=(shuffles_batch & using_regression, no_shuffling & using_regression), \n",
    "          test_name='Regression - Shuffling Batches vs. Not Shuffling Batches:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Regression using ReLU Activation - Shuffling Batches vs. Not Shuffling Batches:\n",
      "********************************************************************************\n",
      "##########\n",
      "train_loss\n",
      "##########\n",
      "Summary for a:\n",
      "n: 517\n",
      "min: 2.6007e-14 - max: 2.7440e+152\n",
      "μ ± 2σ: 1.3287e+148 ± 3.6768e+150\n",
      "Quartiles - 1st: 2.0113e-01 - 2nd: 3.2423e-01 - 3rd: 5.0204e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 519\n",
      "min: 1.1102e-16 - max: 2.9061e+153\n",
      "μ ± 2σ: 2.0791e+149 ± 4.3211e+151\n",
      "Quartiles - 1st: 1.8675e-01 - 2nd: 3.1244e-01 - 3rd: 5.0109e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: -1.3311 - p: .410\n",
      "############\n",
      "train_scores\n",
      "############\n",
      "Summary for a:\n",
      "n: 427\n",
      "min: -1.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 5.4672e-01 ± 1.3455e-02\n",
      "Quartiles - 1st: 1.4938e-01 - 2nd: 6.5393e-01 - 3rd: 9.4019e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 386\n",
      "min: -1.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 5.7362e-01 ± 2.6014e-02\n",
      "Quartiles - 1st: 2.4996e-01 - 2nd: 6.5455e-01 - 3rd: 9.3857e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: -6.5395 - p: <.001\n",
      "########\n",
      "val_loss\n",
      "########\n",
      "Summary for a:\n",
      "n: 140\n",
      "min: 6.4807e-02 - max: 8.4221e+147\n",
      "μ ± 2σ: 1.9354e+144 ± 2.2835e+146\n",
      "Quartiles - 1st: 1.6305e-01 - 2nd: 2.8003e-01 - 3rd: 3.1917e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 143\n",
      "min: 6.3486e-02 - max: 4.4136e+149\n",
      "μ ± 2σ: 6.8538e+145 ± 1.1000e+148\n",
      "Quartiles - 1st: 1.8440e-01 - 2nd: 3.0697e-01 - 3rd: 4.2592e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: -0.9718 - p: .509\n",
      "##########\n",
      "val_scores\n",
      "##########\n",
      "Summary for a:\n",
      "n: 140\n",
      "min: -4.0873e-01 - max: 9.9017e-01\n",
      "μ ± 2σ: 7.3698e-01 ± 3.0535e-02\n",
      "Quartiles - 1st: 6.9253e-01 - 2nd: 7.7224e-01 - 3rd: 9.2628e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 144\n",
      "min: -4.1972e-01 - max: 9.9011e-01\n",
      "μ ± 2σ: 6.3447e-01 ± 1.9517e-02\n",
      "Quartiles - 1st: 5.1049e-01 - 2nd: 7.1371e-01 - 3rd: 9.0704e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: 20.5774 - p: <.001\n"
     ]
    }
   ],
   "source": [
    "using_relu = df['activation_func'] == 'LeakyReLU'\n",
    "\n",
    "stat_test(masks=(shuffles_batch & using_regression & using_relu, no_shuffling & using_regression & using_relu), \n",
    "          test_name='Regression using ReLU Activation - Shuffling Batches vs. Not Shuffling Batches:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Regression using Sigmoid Activation - Shuffling Batches vs. Not Shuffling Batches:\n",
      "********************************************************************************\n",
      "##########\n",
      "train_loss\n",
      "##########\n",
      "Summary for a:\n",
      "n: 560\n",
      "min: 7.2164e-16 - max: 2.1414e+00\n",
      "μ ± 2σ: 3.1824e-01 ± 8.9017e-03\n",
      "Quartiles - 1st: 1.4724e-01 - 2nd: 2.9819e-01 - 3rd: 5.0208e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 554\n",
      "min: 4.4409e-16 - max: 1.9929e+00\n",
      "μ ± 2σ: 3.1560e-01 ± 7.6206e-03\n",
      "Quartiles - 1st: 1.5110e-01 - 2nd: 2.8748e-01 - 3rd: 5.0145e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: 1.5599 - p: .118\n",
      "############\n",
      "train_scores\n",
      "############\n",
      "Summary for a:\n",
      "n: 460\n",
      "min: -1.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 5.4718e-01 ± 1.3379e-02\n",
      "Quartiles - 1st: 3.0323e-03 - 2nd: 6.8760e-01 - 3rd: 9.5232e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 405\n",
      "min: -1.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 6.0757e-01 ± 1.2087e-02\n",
      "Quartiles - 1st: 1.5360e-01 - 2nd: 7.0083e-01 - 3rd: 9.5554e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: -14.0702 - p: <.001\n",
      "########\n",
      "val_loss\n",
      "########\n",
      "Summary for a:\n",
      "n: 162\n",
      "min: 5.5038e-02 - max: 5.3027e-01\n",
      "μ ± 2σ: 2.0279e-01 ± 4.0075e-03\n",
      "Quartiles - 1st: 1.3295e-01 - 2nd: 1.5989e-01 - 3rd: 2.9704e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 162\n",
      "min: 6.3192e-02 - max: 6.2704e-01\n",
      "μ ± 2σ: 2.3388e-01 ± 7.5749e-03\n",
      "Quartiles - 1st: 1.4278e-01 - 2nd: 1.8632e-01 - 3rd: 3.1382e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: -16.9737 - p: <.001\n",
      "##########\n",
      "val_scores\n",
      "##########\n",
      "Summary for a:\n",
      "n: 162\n",
      "min: -4.6464e-01 - max: 9.9346e-01\n",
      "μ ± 2σ: 8.5441e-01 ± 3.3836e-02\n",
      "Quartiles - 1st: 7.3100e-01 - 2nd: 9.2849e-01 - 3rd: 9.5160e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 162\n",
      "min: -5.0256e-01 - max: 9.9000e-01\n",
      "μ ± 2σ: 8.0603e-01 ± 3.1335e-02\n",
      "Quartiles - 1st: 6.9774e-01 - 2nd: 9.0024e-01 - 3rd: 9.4443e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: 16.0851 - p: <.001\n"
     ]
    }
   ],
   "source": [
    "using_sigmoid = df['activation_func'] == 'Sigmoid'\n",
    "\n",
    "stat_test(masks=(shuffles_batch & using_regression & using_sigmoid, \n",
    "                 no_shuffling & using_regression & using_sigmoid), \n",
    "          test_name='Regression using Sigmoid Activation - Shuffling Batches vs. Not Shuffling Batches:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling Batches in Regression Tasks\n",
    "It is difficult to comment on whether or not there is any improvement in loss since the results are not statistically significant. However, there is statistically significant evidence that shuffling batches negatively influences training scores, while also improving generalisation ability (validation scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Classification - Shuffling Batches vs. Not Shuffling Batches:\n",
      "********************************************************************************\n",
      "##########\n",
      "train_loss\n",
      "##########\n",
      "Summary for a:\n",
      "n: 964\n",
      "min: 6.6351e-03 - max: 5.1808e+01\n",
      "μ ± 2σ: 1.4443e+00 ± 6.5767e-01\n",
      "Quartiles - 1st: 4.6527e-01 - 2nd: 6.9411e-01 - 3rd: 8.5949e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 969\n",
      "min: 8.1027e-03 - max: 4.4671e+01\n",
      "μ ± 2σ: 1.5245e+00 ± 7.2667e-01\n",
      "Quartiles - 1st: 4.5403e-01 - 2nd: 6.9411e-01 - 3rd: 9.1865e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: -3.7916 - p: <.001\n",
      "############\n",
      "train_scores\n",
      "############\n",
      "Summary for a:\n",
      "n: 964\n",
      "min: 0.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 7.2481e-01 ± 6.7188e-03\n",
      "Quartiles - 1st: 5.0000e-01 - 2nd: 7.5404e-01 - 3rd: 9.7656e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 972\n",
      "min: 0.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 7.1432e-01 ± 7.1212e-03\n",
      "Quartiles - 1st: 5.0000e-01 - 2nd: 7.5000e-01 - 3rd: 9.7539e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: 5.7401 - p: <.001\n",
      "########\n",
      "val_loss\n",
      "########\n",
      "Summary for a:\n",
      "n: 316\n",
      "min: 9.3317e-05 - max: 1.3816e+01\n",
      "μ ± 2σ: 4.5596e-01 ± 4.6309e-01\n",
      "Quartiles - 1st: 1.0839e-01 - 2nd: 2.1326e-01 - 3rd: 4.4528e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 321\n",
      "min: 8.6399e-07 - max: 1.4401e+01\n",
      "μ ± 2σ: 1.2033e+00 ± 3.4843e-01\n",
      "Quartiles - 1st: 1.0558e-01 - 2nd: 2.0112e-01 - 3rd: 4.5822e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: -25.1743 - p: <.001\n",
      "##########\n",
      "val_scores\n",
      "##########\n",
      "Summary for a:\n",
      "n: 316\n",
      "min: 0.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 9.3027e-01 ± 2.1789e-02\n",
      "Quartiles - 1st: 9.3333e-01 - 2nd: 9.6667e-01 - 3rd: 1.0000e+00\n",
      "\n",
      "Summary for b:\n",
      "n: 324\n",
      "min: 0.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 8.7615e-01 ± 1.3812e-02\n",
      "Quartiles - 1st: 9.0000e-01 - 2nd: 9.6667e-01 - 3rd: 1.0000e+00\n",
      "\n",
      "Welch t-test:\n",
      "t: 25.2836 - p: <.001\n"
     ]
    }
   ],
   "source": [
    "using_classification = df['clf_type'] == 'MLPClassifier'\n",
    "\n",
    "stat_test(masks=(shuffles_batch & using_classification, no_shuffling & using_classification), \n",
    "          test_name='Classification - Shuffling Batches vs. Not Shuffling Batches:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Classification using ReLU Activation - Shuffling Batches vs. Not Shuffling Batches:\n",
      "********************************************************************************\n",
      "##########\n",
      "train_loss\n",
      "##########\n",
      "Summary for a:\n",
      "n: 480\n",
      "min: 6.6351e-03 - max: 5.1808e+01\n",
      "μ ± 2σ: 1.7015e+00 ± 9.8321e-01\n",
      "Quartiles - 1st: 4.3392e-01 - 2nd: 6.9319e-01 - 3rd: 8.1937e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 483\n",
      "min: 8.1027e-03 - max: 4.4671e+01\n",
      "μ ± 2σ: 1.8547e+00 ± 1.0712e+00\n",
      "Quartiles - 1st: 4.4635e-01 - 2nd: 6.9346e-01 - 3rd: 9.0703e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: -3.8645 - p: <.001\n",
      "############\n",
      "train_scores\n",
      "############\n",
      "Summary for a:\n",
      "n: 480\n",
      "min: 0.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 7.5303e-01 ± 1.0009e-02\n",
      "Quartiles - 1st: 5.0000e-01 - 2nd: 8.7500e-01 - 3rd: 9.8333e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 486\n",
      "min: 0.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 7.3373e-01 ± 1.0651e-02\n",
      "Quartiles - 1st: 5.0000e-01 - 2nd: 8.4531e-01 - 3rd: 9.8346e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: 7.7434 - p: <.001\n",
      "########\n",
      "val_loss\n",
      "########\n",
      "Summary for a:\n",
      "n: 156\n",
      "min: 9.3317e-05 - max: 1.3816e+01\n",
      "μ ± 2σ: 5.6946e-01 ± 6.6181e-01\n",
      "Quartiles - 1st: 1.0128e-01 - 2nd: 1.8458e-01 - 3rd: 4.1120e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 159\n",
      "min: 8.6399e-07 - max: 1.4401e+01\n",
      "μ ± 2σ: 1.9429e+00 ± 4.5641e-01\n",
      "Quartiles - 1st: 1.0444e-01 - 2nd: 1.8894e-01 - 3rd: 5.7121e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: -24.5312 - p: <.001\n",
      "##########\n",
      "val_scores\n",
      "##########\n",
      "Summary for a:\n",
      "n: 156\n",
      "min: 0.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 9.2595e-01 ± 2.8957e-02\n",
      "Quartiles - 1st: 9.3333e-01 - 2nd: 9.6667e-01 - 3rd: 1.0000e+00\n",
      "\n",
      "Summary for b:\n",
      "n: 162\n",
      "min: 0.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 8.4409e-01 ± 1.8638e-02\n",
      "Quartiles - 1st: 8.7292e-01 - 2nd: 9.6667e-01 - 3rd: 1.0000e+00\n",
      "\n",
      "Welch t-test:\n",
      "t: 22.8996 - p: <.001\n"
     ]
    }
   ],
   "source": [
    "stat_test(masks=(shuffles_batch & using_classification & using_relu, \n",
    "                 no_shuffling & using_classification & using_relu), \n",
    "          test_name='Classification using ReLU Activation - Shuffling Batches vs. Not Shuffling Batches:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Classification using Sigmoid Activation - Shuffling Batches vs. Not Shuffling Batches:\n",
      "********************************************************************************\n",
      "##########\n",
      "train_loss\n",
      "##########\n",
      "Summary for a:\n",
      "n: 484\n",
      "min: 1.3374e-02 - max: 9.6380e+00\n",
      "μ ± 2σ: 1.1862e+00 ± 8.1926e-02\n",
      "Quartiles - 1st: 4.9731e-01 - 2nd: 6.9466e-01 - 3rd: 9.4391e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 486\n",
      "min: 9.9160e-03 - max: 9.0202e+00\n",
      "μ ± 2σ: 1.1937e+00 ± 1.0534e-01\n",
      "Quartiles - 1st: 4.5220e-01 - 2nd: 6.9446e-01 - 3rd: 9.6443e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: -0.5336 - p: .593\n",
      "############\n",
      "train_scores\n",
      "############\n",
      "Summary for a:\n",
      "n: 484\n",
      "min: 0.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 6.9651e-01 ± 1.0900e-02\n",
      "Quartiles - 1st: 5.0000e-01 - 2nd: 7.4727e-01 - 3rd: 9.7500e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 486\n",
      "min: 0.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 6.9483e-01 ± 9.8338e-03\n",
      "Quartiles - 1st: 5.0000e-01 - 2nd: 7.3359e-01 - 3rd: 9.7500e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: 0.6309 - p: .528\n",
      "########\n",
      "val_loss\n",
      "########\n",
      "Summary for a:\n",
      "n: 160\n",
      "min: 4.1490e-04 - max: 6.9069e+00\n",
      "μ ± 2σ: 3.4259e-01 ± 1.0616e-01\n",
      "Quartiles - 1st: 1.1173e-01 - 2nd: 2.7296e-01 - 3rd: 4.7064e-01\n",
      "\n",
      "Summary for b:\n",
      "n: 162\n",
      "min: 6.4885e-05 - max: 1.3816e+01\n",
      "μ ± 2σ: 4.7187e-01 ± 5.6135e-01\n",
      "Quartiles - 1st: 1.0492e-01 - 2nd: 2.1013e-01 - 3rd: 4.3700e-01\n",
      "\n",
      "Welch t-test:\n",
      "t: -8.2394 - p: <.001\n",
      "##########\n",
      "val_scores\n",
      "##########\n",
      "Summary for a:\n",
      "n: 160\n",
      "min: 0.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 9.3457e-01 ± 2.5521e-02\n",
      "Quartiles - 1st: 9.3333e-01 - 2nd: 9.6667e-01 - 3rd: 1.0000e+00\n",
      "\n",
      "Summary for b:\n",
      "n: 162\n",
      "min: 0.0000e+00 - max: 1.0000e+00\n",
      "μ ± 2σ: 9.0821e-01 ± 2.2640e-02\n",
      "Quartiles - 1st: 9.0000e-01 - 2nd: 9.6667e-01 - 3rd: 1.0000e+00\n",
      "\n",
      "Welch t-test:\n",
      "t: 11.5335 - p: <.001\n"
     ]
    }
   ],
   "source": [
    "stat_test(masks=(shuffles_batch & using_classification & using_sigmoid, \n",
    "                 no_shuffling & using_classification & using_sigmoid), \n",
    "          test_name='Classification using Sigmoid Activation - Shuffling Batches vs. Not Shuffling Batches:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling Batches in Classification Tasks\n",
    "\n",
    "With the exception of the training metrics when using the sigmoid activation, we see statistically significant results. There is a much clearer trend when it comes to classification, we see consistent improvement in all metrics, with more marked improvement in validation performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
